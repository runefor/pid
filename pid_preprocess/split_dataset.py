import json
import random
from pathlib import Path
from collections import defaultdict, Counter
import shutil
from typing import Dict, List, Tuple, Union, Optional
from enum import Enum
import numpy as np
from abc import ABC, abstractmethod


class SplitStrategy(Enum):
    """ë¶„í•  ì „ëµ ì—´ê±°í˜•"""
    DOMINANT_CATEGORY = "dominant_category"
    MULTI_LABEL = "multi_label"
    HYBRID = "hybrid"


class StratifiedDatasetSplitter:
    """
    COCO í˜•ì‹ ë°ì´í„°ì…‹ì„ ìœ„í•œ ì¢…í•© Stratified Split í´ë˜ìŠ¤
    
    ì„¸ ê°€ì§€ ì „ëµ ì§€ì›:
    1. Dominant Category: ì´ë¯¸ì§€ë‹¹ ê°€ì¥ ë§ì€ ì–´ë…¸í…Œì´ì…˜ì„ ê°€ì§„ ì¹´í…Œê³ ë¦¬ ê¸°ì¤€
    2. Multi-label: ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì¡°í•©ì„ ê³ ë ¤í•œ ì •ë°€ ë¶„í• 
    3. Hybrid: Dominant + ì†Œìˆ˜ ì¹´í…Œê³ ë¦¬ ë³´ì •
    """
    
    def __init__(
        self,
        input_json_path: Union[str, Path],
        output_dir: Union[str, Path],
        image_dir: Optional[Union[str, Path]] = None,
        train_ratio: float = 0.7,
        val_ratio: float = 0.2,
        random_seed: int = 42,
        strategy: Union[str, SplitStrategy] = SplitStrategy.HYBRID
    ):
        """
        Args:
            input_json_path: ì…ë ¥ COCO JSON íŒŒì¼ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì´ë¯¸ì§€ ë³µì‚¬ìš©, ì„ íƒì‚¬í•­)
            train_ratio: í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸: 0.7)
            val_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸: 0.2)
            random_seed: ëœë¤ ì‹œë“œ
            strategy: ë¶„í•  ì „ëµ (dominant_category, multi_label, hybrid)
        """
        self.input_json_path = Path(input_json_path)
        self.output_dir = Path(output_dir)
        self.image_dir = Path(image_dir) if image_dir else None
        self.train_ratio = train_ratio
        self.val_ratio = val_ratio
        self.test_ratio = 1.0 - train_ratio - val_ratio
        self.random_seed = random_seed
        
        # ì „ëµ ì„¤ì •
        if isinstance(strategy, str):
            self.strategy = SplitStrategy(strategy)
        else:
            self.strategy = strategy
        
        # ì „ëµë³„ íŒŒë¼ë¯¸í„° (ì‚¬ìš©ìê°€ ìˆ˜ì • ê°€ëŠ¥)
        self.strategy_params = {
            'rare_threshold': 50,           # Hybridìš©: ì†Œìˆ˜ í´ë˜ìŠ¤ ì„ê³„ê°’
            'very_rare_threshold': 10,      # Hybridìš©: ê·¹ì†Œìˆ˜ í´ë˜ìŠ¤ ì„ê³„ê°’  
            'min_samples_per_category': 3,  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
            'min_samples_per_split': 2,     # Splitë‹¹ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
            'rebalance_tolerance': 0.1      # Hybridìš©: ì¬ì¡°ì • í—ˆìš© ì˜¤ì°¨
        }
        
        # ë‚´ë¶€ ë°ì´í„°
        self.data = None
        self.images = None
        self.annotations = None
        self.categories = None
        self.img_to_anns = defaultdict(list)
        self.valid_images = None
        self.class_stats = {}
        
        random.seed(self.random_seed)
    
    def set_strategy_params(self, **params):
        """ì „ëµë³„ íŒŒë¼ë¯¸í„° ì„¤ì •"""
        self.strategy_params.update(params)
        return self
    
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print(f"ğŸ“ Loading data from: {self.input_json_path}")
        
        with open(self.input_json_path, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        self.images = self.data['images']
        self.annotations = self.data['annotations']
        self.categories = self.data['categories']
        
        print(f"ğŸ“Š Dataset Overview:")
        print(f"   Total images: {len(self.images):,}")
        print(f"   Total annotations: {len(self.annotations):,}")
        print(f"   Total categories: {len(self.categories):,}")
        
        # ì´ë¯¸ì§€ë³„ ì–´ë…¸í…Œì´ì…˜ ë§¤í•‘
        self.img_to_anns = defaultdict(list)
        for ann in self.annotations:
            self.img_to_anns[ann['image_id']].append(ann)
        
        # ì–´ë…¸í…Œì´ì…˜ì´ ìˆëŠ” ì´ë¯¸ì§€ë§Œ í•„í„°ë§
        self.valid_images = [img for img in self.images if img['id'] in self.img_to_anns]
        print(f"   Valid images (with annotations): {len(self.valid_images):,}")
        
        # í´ë˜ìŠ¤ë³„ í†µê³„ ë¶„ì„
        self._analyze_class_statistics()
        
        return self
    
    def split(self) -> Dict[str, Dict[str, int]]:
        """ì„ íƒëœ ì „ëµìœ¼ë¡œ ë°ì´í„° ë¶„í•  ì‹¤í–‰"""
        if self.data is None:
            self.load_data()
        
        print(f"\nğŸ”„ Applying {self.strategy.value} strategy...")
        
        # ì „ëµë³„ ë¶„í•  ì‹¤í–‰
        if self.strategy == SplitStrategy.DOMINANT_CATEGORY:
            splits = self._dominant_category_split()
        elif self.strategy == SplitStrategy.MULTI_LABEL:
            splits = self._multi_label_split()
        elif self.strategy == SplitStrategy.HYBRID:
            splits = self._hybrid_split()
        else:
            raise ValueError(f"Unknown strategy: {self.strategy}")
        
        # ê²°ê³¼ ì €ì¥ ë° ê²€ì¦
        stats = self._save_and_validate_splits(splits)
        
        return stats
    
    def _analyze_class_statistics(self):
        """í´ë˜ìŠ¤ë³„ ìƒì„¸ í†µê³„ ë¶„ì„"""
        # ì „ì²´ í´ë˜ìŠ¤ë³„ ì–´ë…¸í…Œì´ì…˜ ìˆ˜
        total_class_counts = Counter()
        for img in self.valid_images:
            for ann in self.img_to_anns[img['id']]:
                total_class_counts[ann['category_id']] += 1
        
        # í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ (í•´ë‹¹ í´ë˜ìŠ¤ê°€ dominantì¸ ì´ë¯¸ì§€)
        dominant_image_counts = Counter()
        for img in self.valid_images:
            class_counts = Counter()
            for ann in self.img_to_anns[img['id']]:
                class_counts[ann['category_id']] += 1
            
            if class_counts:
                dominant_class = class_counts.most_common(1)[0][0]
                dominant_image_counts[dominant_class] += 1
        
        # í†µê³„ ì •ë¦¬
        category_dict = {cat['id']: cat['name'] for cat in self.categories}
        
        for class_id in total_class_counts.keys():
            self.class_stats[class_id] = {
                'name': category_dict.get(class_id, f'Unknown_{class_id}'),
                'total_annotations': total_class_counts[class_id],
                'dominant_images': dominant_image_counts.get(class_id, 0),
                'appears_in_images': len([1 for img in self.valid_images 
                                        if any(ann['category_id'] == class_id 
                                              for ann in self.img_to_anns[img['id']])])
            }
        
        # ë¶ˆê· í˜• ì •ë„ ê³„ì‚°
        counts = list(total_class_counts.values())
        if counts:
            max_count = max(counts)
            min_count = min(counts)
            imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')
            
            print(f"ğŸ“ˆ Class Distribution Analysis:")
            print(f"   Most frequent class: {max_count:,} annotations")
            print(f"   Least frequent class: {min_count:,} annotations") 
            print(f"   Imbalance ratio: {imbalance_ratio:.1f}:1")
            
            # ë¶„í¬ ì¶”ì²œ
            if imbalance_ratio < 10:
                recommended = "dominant_category"
            elif imbalance_ratio < 100:
                recommended = "hybrid"
            else:
                recommended = "multi_label"
            
            if self.strategy.value != recommended:
                print(f"ğŸ’¡ Recommended strategy for this dataset: {recommended}")
                print(f"   (Currently using: {self.strategy.value})")
    
    def _dominant_category_split(self) -> Dict[str, List[Dict]]:
        """Dominant Category ê¸°ë°˜ ë¶„í• """
        print("   Using dominant category per image...")
        
        # í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê·¸ë£¹í™”
        class_to_images = defaultdict(list)
        
        for img in self.valid_images:
            class_counts = Counter()
            for ann in self.img_to_anns[img['id']]:
                class_counts[ann['category_id']] += 1
            
            if class_counts:
                # ë™ì ì‹œ í´ë˜ìŠ¤ IDê°€ ì‘ì€ ê²ƒì„ ìš°ì„  ì„ íƒ (ì¼ê´€ì„± ìœ„í•´)
                sorted_classes = sorted(class_counts.items(), 
                                      key=lambda x: (-x[1], x[0]))
                dominant_class = sorted_classes[0][0]
                class_to_images[dominant_class].append(img)
        
        return self._split_by_class_groups(class_to_images)
    
    def _multi_label_split(self) -> Dict[str, List[Dict]]:
        """Multi-label ê¸°ë°˜ ë¶„í•  (ì¹´í…Œê³ ë¦¬ ì¡°í•© ê³ ë ¤)"""
        print("   Using multi-label combinations...")
        
        # ì´ë¯¸ì§€ë³„ ì¹´í…Œê³ ë¦¬ ì¡°í•© ìƒì„±
        combination_to_images = defaultdict(list)
        
        for img in self.valid_images:
            categories_in_image = set()
            for ann in self.img_to_anns[img['id']]:
                categories_in_image.add(ann['category_id'])
            
            # frozensetìœ¼ë¡œ ì¡°í•© ìƒì„± (ìˆœì„œ ë¬´ê´€)
            combination = frozenset(categories_in_image)
            combination_to_images[combination].append(img)
        
        print(f"   Found {len(combination_to_images)} unique category combinations")
        
        # ì¡°í•©ë³„ ë¶„í• 
        splits = {"train": [], "val": [], "test": []}
        
        for combination, comb_images in combination_to_images.items():
            n_images = len(comb_images)
            
            if n_images < self.strategy_params['min_samples_per_category']:
                # ìƒ˜í”Œì´ ë„ˆë¬´ ì ìœ¼ë©´ trainì— ëª¨ë‘ í• ë‹¹
                splits["train"].extend(comb_images)
                continue
            
            # ë¹„ìœ¨ì— ë”°ë¼ ë¶„í• 
            random.shuffle(comb_images)
            
            n_train = max(1, int(n_images * self.train_ratio))
            n_val = max(1, int(n_images * self.val_ratio))
            
            splits["train"].extend(comb_images[:n_train])
            splits["val"].extend(comb_images[n_train:n_train + n_val])
            splits["test"].extend(comb_images[n_train + n_val:])
        
        return splits
    
    def _hybrid_split(self) -> Dict[str, List[Dict]]:
        """Hybrid ë°©ì‹: Dominant Category + ì†Œìˆ˜ í´ë˜ìŠ¤ ë³´ì •"""
        print("   Using hybrid approach (dominant + rare class rebalancing)...")
        
        # 1ë‹¨ê³„: í´ë˜ìŠ¤ë¥¼ í‹°ì–´ë³„ë¡œ ë¶„ë¥˜
        rare_threshold = self.strategy_params['rare_threshold']
        very_rare_threshold = self.strategy_params['very_rare_threshold']
        
        class_tiers = self._classify_class_tiers(rare_threshold, very_rare_threshold)
        
        # 2ë‹¨ê³„: ì´ë¯¸ì§€ë³„ dominant class ê²°ì • (ì†Œìˆ˜ í´ë˜ìŠ¤ ìš°ì„ ìˆœìœ„ ë¶€ì—¬)
        class_to_images = defaultdict(list)
        
        for img in self.valid_images:
            class_counts = Counter()
            for ann in self.img_to_anns[img['id']]:
                class_counts[ann['category_id']] += 1
            
            if class_counts:
                # ì†Œìˆ˜ í´ë˜ìŠ¤ê°€ ìˆìœ¼ë©´ ìš°ì„ ìˆœìœ„ ë¶€ì—¬
                rare_classes = [cls for cls in class_counts.keys() 
                              if cls in class_tiers['rare'] or cls in class_tiers['very_rare']]
                
                if rare_classes:
                    # ì†Œìˆ˜ í´ë˜ìŠ¤ ì¤‘ ê°€ì¥ ë§ì€ ê²ƒì„ ì„ íƒ
                    dominant_class = max(rare_classes, key=lambda x: class_counts[x])
                else:
                    # ì¼ë°˜ì ì¸ dominant class ì„ íƒ
                    dominant_class = class_counts.most_common(1)[0][0]
                
                class_to_images[dominant_class].append(img)
        
        # 3ë‹¨ê³„: í‹°ì–´ë³„ë¡œ ë‹¤ë¥¸ ë¶„í•  ì „ëµ ì ìš©
        return self._split_by_tiers(class_to_images, class_tiers)
    
    def _classify_class_tiers(self, rare_threshold, very_rare_threshold):
        """í´ë˜ìŠ¤ë¥¼ í‹°ì–´ë³„ë¡œ ë¶„ë¥˜"""
        tiers = {
            'major': [],
            'medium': [],
            'rare': [],
            'very_rare': []
        }
        
        for class_id, stats in self.class_stats.items():
            count = stats['total_annotations']
            
            if count < very_rare_threshold:
                tiers['very_rare'].append(class_id)
            elif count < rare_threshold:
                tiers['rare'].append(class_id)
            elif count < 1000:
                tiers['medium'].append(class_id)
            else:
                tiers['major'].append(class_id)
        
        print(f"   Class tiers: Major({len(tiers['major'])}), "
              f"Medium({len(tiers['medium'])}), "
              f"Rare({len(tiers['rare'])}), "
              f"VeryRare({len(tiers['very_rare'])})")
        
        return tiers
    
    def _split_by_class_groups(self, class_to_images):
        """í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê·¸ë£¹ì„ ë¶„í• """
        splits = {"train": [], "val": [], "test": []}
        
        for class_id, images in class_to_images.items():
            if len(images) < self.strategy_params['min_samples_per_category']:
                splits["train"].extend(images)
                continue
            
            random.shuffle(images)
            
            n_train = max(1, int(len(images) * self.train_ratio))
            n_val = max(1, int(len(images) * self.val_ratio))
            
            splits["train"].extend(images[:n_train])
            splits["val"].extend(images[n_train:n_train + n_val])
            splits["test"].extend(images[n_train + n_val:])
        
        return splits
    
    def _split_by_tiers(self, class_to_images, class_tiers):
        """í‹°ì–´ë³„ë¡œ ë‹¤ë¥¸ ì „ëµìœ¼ë¡œ ë¶„í• """
        splits = {"train": [], "val": [], "test": []}
        min_split_samples = self.strategy_params['min_samples_per_split']
        
        for tier_name, class_ids in class_tiers.items():
            for class_id in class_ids:
                images = class_to_images.get(class_id, [])
                if not images:
                    continue
                
                n_images = len(images)
                random.shuffle(images)
                
                if tier_name == 'very_rare':
                    # ê·¹ì†Œìˆ˜: ëŒ€ë¶€ë¶„ train, ìµœì†Œí•œì˜ val
                    if n_images >= 3:
                        splits["train"].extend(images[:-1])
                        splits["val"].extend(images[-1:])
                    else:
                        splits["train"].extend(images)
                        
                elif tier_name == 'rare':
                    # ì†Œìˆ˜: ë³´ìˆ˜ì  ë¶„í•  (80:15:5)
                    if n_images >= min_split_samples * 3:
                        n_train = max(min_split_samples, int(n_images * 0.8))
                        n_val = max(1, int(n_images * 0.15))
                        
                        splits["train"].extend(images[:n_train])
                        splits["val"].extend(images[n_train:n_train + n_val])
                        splits["test"].extend(images[n_train + n_val:])
                    else:
                        splits["train"].extend(images)
                        
                else:
                    # ì¼ë°˜: í‘œì¤€ ë¹„ìœ¨ ë¶„í• 
                    n_train = int(n_images * self.train_ratio)
                    n_val = int(n_images * self.val_ratio)
                    
                    splits["train"].extend(images[:n_train])
                    splits["val"].extend(images[n_train:n_train + n_val])
                    splits["test"].extend(images[n_train + n_val:])
        
        return splits
    
    def _save_and_validate_splits(self, splits):
        """ë¶„í•  ê²°ê³¼ ì €ì¥ ë° ê²€ì¦"""
        self.output_dir.mkdir(exist_ok=True)
        (self.output_dir / "annotations").mkdir(exist_ok=True)
        
        stats = {}
        
        for split_name, split_images in splits.items():
            if not split_images:
                continue
            
            # í•´ë‹¹ splitì˜ ì–´ë…¸í…Œì´ì…˜ ìˆ˜ì§‘
            split_annotations = []
            for img in split_images:
                split_annotations.extend(self.img_to_anns[img['id']])
            
            # ID ì¬í• ë‹¹
            split_images_copy = [img.copy() for img in split_images]
            split_annotations_copy = [ann.copy() for ann in split_annotations]
            
            self._reassign_ids(split_images_copy, split_annotations_copy)
            
            # JSON ì €ì¥
            split_data = {
                'info': self.data.get('info', {}),
                'licenses': self.data.get('licenses', []),
                'images': split_images_copy,
                'annotations': split_annotations_copy,
                'categories': self.categories
            }
            
            json_path = self.output_dir / "annotations" / f'{split_name}.json'
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(split_data, f, ensure_ascii=False, indent=2)
            
            # ì´ë¯¸ì§€ ë³µì‚¬ (ì˜µì…˜)
            if self.image_dir:
                self._copy_images(split_images, self.output_dir / split_name)
            
            # í†µê³„ ìˆ˜ì§‘
            class_counts = Counter()
            for ann in split_annotations_copy:
                class_counts[ann['category_id']] += 1
            
            stats[split_name] = {
                'images': len(split_images_copy),
                'annotations': len(split_annotations_copy),
                'categories': dict(class_counts)
            }
            
            print(f"   {split_name}: {len(split_images_copy):,} images, "
                  f"{len(split_annotations_copy):,} annotations")
        
        # ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
        self._generate_validation_report(stats)
        
        print(f"\nâœ… Split completed! Results saved to: {self.output_dir}")
        
        return stats
    
    def _reassign_ids(self, images, annotations):
        """ID ì¬í• ë‹¹"""
        old_to_new_image_id = {}
        for i, img in enumerate(images, 1):
            old_id = img['id']
            img['id'] = i
            old_to_new_image_id[old_id] = i
        
        for i, ann in enumerate(annotations, 1):
            ann['id'] = i
            ann['image_id'] = old_to_new_image_id[ann['image_id']]
    
    def _copy_images(self, images, dst_dir):
        """ì´ë¯¸ì§€ ë³µì‚¬"""
        if not self.image_dir or not self.image_dir.exists():
            print(f"   Warning: Image directory not found: {self.image_dir}")
            return
        
        dst_dir.mkdir(exist_ok=True)
        
        copied = 0
        for img in images:
            src_path = self.image_dir / img['file_name']
            dst_path = dst_dir / img['file_name']
            
            if src_path.exists():
                shutil.copy2(src_path, dst_path)
                copied += 1
        
        print(f"   Copied {copied}/{len(images)} images")
    
    def _generate_validation_report(self, stats):
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        print(f"\n" + "="*50)
        print(f"ğŸ“‹ STRATIFIED SPLIT VALIDATION ({self.strategy.value.upper()})")
        print("="*50)
        
        category_dict = {cat['id']: cat['name'] for cat in self.categories}
        
        # ì „ì²´ í†µê³„
        total_images = sum(split_stats['images'] for split_stats in stats.values())
        total_annotations = sum(split_stats['annotations'] for split_stats in stats.values())
        
        print(f"Overall Distribution:")
        for split_name, split_stats in stats.items():
            img_pct = split_stats['images'] / total_images * 100
            ann_pct = split_stats['annotations'] / total_annotations * 100
            print(f"  {split_name:5}: {split_stats['images']:5,} images ({img_pct:5.1f}%), "
                  f"{split_stats['annotations']:6,} annotations ({ann_pct:5.1f}%)")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ (ìƒìœ„ 20ê°œë§Œ)
        print(f"\nTop 20 Categories Distribution:")
        print(f"{'Category':<30} {'Train':>8} {'Val':>8} {'Test':>8} {'Total':>8}")
        print("-" * 70)
        
        # ì „ì²´ ì¹´í…Œê³ ë¦¬ë¥¼ ì–´ë…¸í…Œì´ì…˜ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        all_categories = set()
        for split_stats in stats.values():
            all_categories.update(split_stats['categories'].keys())
        
        category_totals = {}
        for cat_id in all_categories:
            total = sum(stats[split]['categories'].get(cat_id, 0) 
                       for split in ['train', 'val', 'test'])
            category_totals[cat_id] = total
        
        # ìƒìœ„ 20ê°œ ì¹´í…Œê³ ë¦¬ ì¶œë ¥
        sorted_categories = sorted(category_totals.items(), key=lambda x: x[1], reverse=True)
        
        for cat_id, total in sorted_categories[:20]:
            cat_name = category_dict.get(cat_id, f'Unknown_{cat_id}')[:28]
            train_count = stats.get('train', {}).get('categories', {}).get(cat_id, 0)
            val_count = stats.get('val', {}).get('categories', {}).get(cat_id, 0)
            test_count = stats.get('test', {}).get('categories', {}).get(cat_id, 0)
            
            print(f"{cat_name:<30} {train_count:8,} {val_count:8,} {test_count:8,} {total:8,}")
        
        if len(sorted_categories) > 20:
            print(f"... and {len(sorted_categories) - 20} more categories")


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_splitter(
    input_json: Union[str, Path],
    output_dir: Union[str, Path],
    strategy: str = "hybrid",
    **kwargs
) -> StratifiedDatasetSplitter:
    """ê°„í¸í•œ splitter ìƒì„± í•¨ìˆ˜"""
    return StratifiedDatasetSplitter(
        input_json_path=input_json,
        output_dir=output_dir,
        strategy=strategy,
        **kwargs
    )


def quick_split(
    input_json: Union[str, Path],
    output_dir: Union[str, Path],
    strategy: str = "hybrid",
    train_ratio: float = 0.7,
    val_ratio: float = 0.2,
    **kwargs
) -> Dict[str, Dict[str, int]]:
    """ì›ìƒ· ë¶„í•  í•¨ìˆ˜"""
    splitter = create_splitter(
        input_json=input_json,
        output_dir=output_dir,
        strategy=strategy,
        train_ratio=train_ratio,
        val_ratio=val_ratio,
        **kwargs
    )
    
    return splitter.split()


# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def compare_strategies(
    input_json: Union[str, Path],
    output_base_dir: Union[str, Path] = "strategy_comparison",
    strategies: List[str] = None
) -> Dict[str, Dict[str, Dict[str, int]]]:
    """ì—¬ëŸ¬ ì „ëµì„ ë¹„êµí•˜ëŠ” í•¨ìˆ˜"""
    if strategies is None:
        strategies = ["dominant_category", "multi_label", "hybrid"]
    
    results = {}
    output_base = Path(output_base_dir)
    
    for strategy in strategies:
        print(f"\nğŸ”„ Comparing strategy: {strategy}")
        try:
            stats = quick_split(
                input_json=input_json,
                output_dir=output_base / strategy,
                strategy=strategy
            )
            results[strategy] = stats
            
        except Exception as e:
            print(f"âŒ Error with {strategy}: {e}")
            results[strategy] = None
    
    # ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±
    _generate_comparison_report(results)
    return results


def _generate_comparison_report(results):
    """ì „ëµ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"""
    print(f"\n" + "="*60)
    print("ğŸ“Š STRATEGY COMPARISON REPORT")
    print("="*60)
    
    print(f"{'Strategy':<20} {'Train':<8} {'Val':<8} {'Test':<8} {'Total Ann.':<12}")
    print("-" * 60)
    
    for strategy, stats in results.items():
        if stats is None:
            print(f"{strategy:<20} {'ERROR':<8} {'ERROR':<8} {'ERROR':<8} {'ERROR':<12}")
            continue
            
        train_imgs = stats.get('train', {}).get('images', 0)
        val_imgs = stats.get('val', {}).get('images', 0) 
        test_imgs = stats.get('test', {}).get('images', 0)
        total_ann = sum(split_data.get('annotations', 0) for split_data in stats.values())
        
        print(f"{strategy:<20} {train_imgs:<8,} {val_imgs:<8,} {test_imgs:<8,} {total_ann:<12,}")


def analyze_dataset_characteristics(input_json: Union[str, Path]) -> Dict:
    """ë°ì´í„°ì…‹ íŠ¹ì„± ë¶„ì„í•˜ì—¬ ìµœì  ì „ëµ ì¶”ì²œ"""
    print("ğŸ” Analyzing dataset characteristics...")
    
    with open(input_json, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    images = data['images']
    annotations = data['annotations']
    categories = data['categories']
    
    # ê¸°ë³¸ í†µê³„
    img_to_anns = defaultdict(list)
    for ann in annotations:
        img_to_anns[ann['image_id']].append(ann)
    
    valid_images = [img for img in images if img['id'] in img_to_anns]
    
    # í´ë˜ìŠ¤ë³„ ë¶„í¬
    class_counts = Counter()
    for img in valid_images:
        for ann in img_to_anns[img['id']]:
            class_counts[ann['category_id']] += 1
    
    # ì´ë¯¸ì§€ë‹¹ í‰ê·  ì¹´í…Œê³ ë¦¬ ìˆ˜
    avg_categories_per_image = sum(len(anns) for anns in img_to_anns.values()) / len(valid_images)
    
    # ë¶ˆê· í˜• ì •ë„
    counts = list(class_counts.values())
    max_count = max(counts) if counts else 0
    min_count = min(counts) if counts else 0
    imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')
    
    # ì¹´í…Œê³ ë¦¬ ì¡°í•© ë³µì¡ë„
    combinations = set()
    for img in valid_images:
        categories_in_img = frozenset(ann['category_id'] for ann in img_to_anns[img['id']])
        combinations.add(categories_in_img)
    
    characteristics = {
        'total_images': len(valid_images),
        'total_categories': len(categories),
        'imbalance_ratio': imbalance_ratio,
        'avg_categories_per_image': avg_categories_per_image,
        'unique_combinations': len(combinations),
        'class_distribution': dict(class_counts)
    }
    
    # ì „ëµ ì¶”ì²œ
    if imbalance_ratio < 10:
        recommended_strategy = "dominant_category"
        reason = "Low imbalance, simple approach sufficient"
    elif imbalance_ratio < 100:
        recommended_strategy = "hybrid" 
        reason = "Moderate imbalance, hybrid approach optimal"
    else:
        recommended_strategy = "multi_label"
        reason = "High imbalance, precise distribution needed"
    
    characteristics['recommended_strategy'] = recommended_strategy
    characteristics['recommendation_reason'] = reason
    
    print(f"ğŸ“ˆ Dataset Analysis Results:")
    print(f"   Total images: {characteristics['total_images']:,}")
    print(f"   Total categories: {characteristics['total_categories']:,}")
    print(f"   Imbalance ratio: {imbalance_ratio:.1f}:1")
    print(f"   Avg categories per image: {avg_categories_per_image:.2f}")
    print(f"   Unique combinations: {characteristics['unique_combinations']:,}")
    print(f"\nğŸ’¡ Recommended strategy: {recommended_strategy}")
    print(f"   Reason: {reason}")
    
    return characteristics


def validate_split_quality(stats: Dict[str, Dict[str, int]], 
                          min_val_ratio: float = 0.1,
                          min_test_ratio: float = 0.05) -> Dict[str, bool]:
    """ë¶„í•  í’ˆì§ˆ ê²€ì¦"""
    quality_check = {
        'adequate_validation_size': False,
        'adequate_test_size': False, 
        'no_empty_splits': False,
        'balanced_distribution': False
    }
    
    total_images = sum(split_data['images'] for split_data in stats.values())
    
    if total_images == 0:
        return quality_check
    
    val_ratio = stats.get('val', {}).get('images', 0) / total_images
    test_ratio = stats.get('test', {}).get('images', 0) / total_images
    
    quality_check['adequate_validation_size'] = val_ratio >= min_val_ratio
    quality_check['adequate_test_size'] = test_ratio >= min_test_ratio
    quality_check['no_empty_splits'] = all(split_data.get('images', 0) > 0 
                                          for split_data in stats.values())
    
    # ë¶„í¬ ê· í˜•ì„± ì²´í¬ (trainì´ ë„ˆë¬´ ì¹˜ìš°ì¹˜ì§€ ì•Šì•˜ëŠ”ì§€)
    train_ratio = stats.get('train', {}).get('images', 0) / total_images
    quality_check['balanced_distribution'] = 0.5 <= train_ratio <= 0.9
    
    return quality_check


if __name__ == "__main__":
    # ğŸ¯ ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œë“¤
    
    print("ğŸš€ Starting comprehensive dataset splitting examples...")
    
    # 1. ë°ì´í„°ì…‹ íŠ¹ì„± ë¶„ì„ ë° ì¶”ì²œ
    characteristics = analyze_dataset_characteristics("assets/merged_dataset.json")
    recommended_strategy = characteristics['recommended_strategy']
    
    # 2. ì¶”ì²œ ì „ëµìœ¼ë¡œ ë¶„í• 
    print(f"\nğŸ¯ Using recommended strategy: {recommended_strategy}")
    stats = quick_split(
        input_json="assets/merged_dataset.json",
        output_dir=f"assets/recommended_split_{recommended_strategy}",
        strategy=recommended_strategy,
        image_dir="assets/images"
    )
    
    # 3. í’ˆì§ˆ ê²€ì¦
    quality = validate_split_quality(stats)
    print(f"\nâœ… Quality Check: {quality}")
    
    # 4. ì—¬ëŸ¬ ì „ëµ ë¹„êµ (ì„ íƒì )
    compare_all = input("\nğŸ¤” Compare all strategies? (y/n): ").lower().strip() == 'y'
    if compare_all:
        comparison_results = compare_strategies(
            input_json="assets/merged_dataset.json",
            output_base_dir="assets/strategy_comparison"
        )
    
    print("\nğŸ‰ All examples completed!")
    
    # 5. ì‚¬ìš©ì ë§ì¶¤í˜• ì„¤ì • ì˜ˆì‹œ (ê·¹ì‹¬í•œ ë¶ˆê· í˜•ìš©)
    if characteristics['imbalance_ratio'] > 100:
        print(f"\nExtreme imbalance detected ({characteristics['imbalance_ratio']:.1f}:1)")
        print("ğŸ”§ Creating custom split for extreme imbalance...")
        
        custom_splitter = create_splitter(
            input_json="assets/merged_dataset.json",
            output_dir="assets/extreme_custom_split",
            strategy="hybrid",
            train_ratio=0.8,  # ë” ë§ì´ trainì— í• ë‹¹
            val_ratio=0.15
        )
        
        custom_splitter.set_strategy_params(
            rare_threshold=min(100, max(characteristics['class_distribution'].values()) // 50),
            very_rare_threshold=min(20, max(characteristics['class_distribution'].values()) // 200),
            min_samples_per_category=2,
            min_samples_per_split=1
        )
        
        custom_stats = custom_splitter.split()
        print("âœ… Custom extreme imbalance split completed!")
    
    print(f"\nğŸ All dataset splitting operations completed successfully!")