# main_preprocess_pipeline.py
import dataclasses
import os
from collections import Counter, defaultdict
from pathlib import Path

import matplotlib.pyplot as plt
import seaborn as sns

from pid_preprocess.data_loader import DataLoader, setting_categories_data
from pid_preprocess.feature_engineering import add_bbox_features
from pid_preprocess import eda_runner
from utils.file_utils import load_json_data


def data_pipeline():
    print("data pipeline start")
    
    base_dir = Path(os.getcwd()).resolve()
    data_path = base_dir / "assets"
    
    save_path = base_dir / "reports"
    
    categories_df = setting_categories_data(data_path=data_path, json_file_name="categories.json")
    
    train_data_loader = DataLoader(dataPath=data_path, jsonDir="preprocessed_data_json", isLog=False)
    test_data_loader = DataLoader(dataPath=data_path, jsonDir="preprocessed_data_json", isLog=False)
    
    train_data = train_data_loader.load_data("TL_prepro/TL_*_*/*.json")
    test_data = test_data_loader.load_data("VL_prepro/VL_*_*/*.json")
    
    train_processed_annotations = add_bbox_features(train_data.annotations)
    train_data = dataclasses.replace(train_data, annotations=train_processed_annotations)
    test_precessed_annotations = add_bbox_features(test_data.annotations)
    test_data = dataclasses.replace(test_data, annotations=test_precessed_annotations)
    
    # eda_runner.run_bbox_analysis(train_data, categories_df, save_path, prefix="train")
    # eda_runner.run_bbox_analysis(test_data, categories_df, save_path, prefix="test")
    
    # eda_runner.run_class_distribution_analysis(train_data, categories_df, save_path, prefix="train")
    # eda_runner.run_class_distribution_analysis(test_data, categories_df, save_path, prefix="test")
    
    eda_runner.run_image_property_analysis(train_data, save_path, prefix="train")
    eda_runner.run_image_property_analysis(test_data, save_path, prefix="test")
    
    eda_runner.run_train_test_comparison(train_data, test_data, categories_df, save_path)

def test_visualize_class_distribution():
    """
    merged_dataset.json íŒŒì¼ì˜ í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    print("ğŸ“Š Starting class distribution visualization...")

    # --- 1. ê²½ë¡œ ì„¤ì • ---
    base_dir = Path(os.getcwd()).resolve()
    data_path = base_dir / "assets"
    report_path = base_dir / "reports"
    figure_path = report_path / "figures"

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    figure_path.mkdir(parents=True, exist_ok=True)

    # --- 2. ë°ì´í„° ë¡œë“œ ---
    json_file_path = data_path / "merged_dataset.json"
    if not json_file_path.exists():
        print(f"âŒ Error: File not found at {json_file_path}")
        return

    print(f"   Loading data from {json_file_path}...")
    coco_data = load_json_data(json_file_path)
    annotations = coco_data.get("annotations", [])
    categories = coco_data.get("categories", [])

    if not annotations or not categories:
        print("   âš ï¸ Annotations or categories are missing in the JSON file.")
        return

    # --- 3. ë°ì´í„° ë¶„ì„ ---
    # ì¹´í…Œê³ ë¦¬ IDì™€ ì´ë¦„ ë§¤í•‘
    id_to_name = {cat["id"]: cat["name"] for cat in categories}

    # ì–´ë…¸í…Œì´ì…˜ì—ì„œ ì¹´í…Œê³ ë¦¬ ID ì¹´ìš´íŠ¸
    class_counts = Counter(ann["category_id"] for ann in annotations)

    # ì¹´ìš´íŠ¸ëœ IDë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ê°œìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    class_distribution = sorted(
        [(id_to_name.get(cat_id, f"Unknown({cat_id})"), count) for cat_id, count in class_counts.items()],
        key=lambda item: item[1],
        reverse=True
    )

    # --- 4. ì‹œê°í™” ---
    plt.style.use('seaborn-v0_8-whitegrid')
    # fig, ax ê°ì²´ë¥¼ ë°›ì•„ì™€ì„œ ì„¸ë¶€ì ì¸ ì„¤ì •ì„ í•©ë‹ˆë‹¤.
    fig, ax = plt.subplots(figsize=(14, 24)) # ê°€ë¡œ ê¸¸ì´ë¥¼ ëŠ˜ë ¤ ìˆ«ì í‘œì‹œ ê³µê°„ í™•ë³´

    class_names, counts = zip(*class_distribution)
    sns.barplot(x=list(counts), y=list(class_names), orient='h', ax=ax)

    # ê° ë§‰ëŒ€(bar)ì— ì •í™•í•œ ìˆ˜ì¹˜ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
    # ax.containers[0]ëŠ” barplotì´ ìƒì„±í•œ ë§‰ëŒ€ ê·¸ë£¹ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
    # fmt='{:,.0f}'ëŠ” ìˆ«ìë¥¼ ì²œ ë‹¨ìœ„ ì½¤ë§ˆë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    ax.bar_label(ax.containers[0], fmt='{:,.0f}', padding=5, fontsize=10)

    ax.set_title('Class Distribution in merged_dataset.json', fontsize=16)
    ax.set_xlabel('Number of Annotations', fontsize=12)
    ax.set_ylabel('Class Name', fontsize=12)
    ax.set_xlim(right=max(counts) * 1.15) # ìˆ«ì ë ˆì´ë¸”ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ xì¶• ë²”ìœ„ í™•ì¥
    plt.tight_layout()

    # --- 5. ê²°ê³¼ ì €ì¥ ---
    save_file = figure_path / "merged_dataset_class_distribution.png"
    plt.savefig(save_file)
    print(f"   âœ… Visualization saved to: {save_file}")

def test_visualize_rare_class_locality():
    """
    ì–´ë…¸í…Œì´ì…˜ì´ 100ê°œ ì´í•˜ì¸ ì†Œìˆ˜ í´ë˜ìŠ¤ë“¤ì´
    ì†Œìˆ˜ì˜ ì´ë¯¸ì§€ì— ì§‘ì¤‘ë˜ì–´ ìˆëŠ”ì§€, ì—¬ëŸ¬ ì´ë¯¸ì§€ì— í©ì–´ì ¸ ìˆëŠ”ì§€ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    print("ğŸ”¬ Starting rare class locality visualization...")

    # --- 1. ê²½ë¡œ ë° íŒŒë¼ë¯¸í„° ì„¤ì • ---
    base_dir = Path(os.getcwd()).resolve()
    data_path = base_dir / "assets"
    figure_path = base_dir / "reports" / "figures"
    figure_path.mkdir(parents=True, exist_ok=True)

    rare_threshold = 100

    # --- 2. ë°ì´í„° ë¡œë“œ ---
    json_file_path = data_path / "merged_dataset.json"
    if not json_file_path.exists():
        print(f"âŒ Error: File not found at {json_file_path}")
        return

    print(f"   Loading data from {json_file_path}...")
    coco_data = load_json_data(json_file_path)
    annotations = coco_data.get("annotations", [])
    categories = coco_data.get("categories", [])

    if not annotations or not categories:
        print("   âš ï¸ Annotations or categories are missing in the JSON file.")
        return

    # --- 3. ë°ì´í„° ë¶„ì„ ---
    id_to_name = {cat["id"]: cat["name"] for cat in categories}

    # ì „ì²´ í´ë˜ìŠ¤ë³„ ì–´ë…¸í…Œì´ì…˜ ìˆ˜ ê³„ì‚°
    total_class_counts = Counter(ann["category_id"] for ann in annotations)

    # ì†Œìˆ˜ í´ë˜ìŠ¤(rare class) ID í•„í„°ë§
    rare_class_ids = {
        cat_id for cat_id, count in total_class_counts.items() if count <= rare_threshold
    }

    # ì†Œìˆ˜ í´ë˜ìŠ¤ê°€ ë“±ì¥í•˜ëŠ” ì´ë¯¸ì§€ ID ìˆ˜ì§‘
    class_to_images = defaultdict(set)
    for ann in annotations:
        if ann["category_id"] in rare_class_ids:
            class_to_images[ann["category_id"]].add(ann["image_id"])

    # ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„° êµ¬ì¡° ìƒì„±: (í´ë˜ìŠ¤ëª…, ì´ ì–´ë…¸í…Œì´ì…˜ ìˆ˜, ê³ ìœ  ì´ë¯¸ì§€ ìˆ˜)
    locality_data = []
    for cat_id in rare_class_ids:
        class_name = id_to_name.get(cat_id, f"Unknown({cat_id})")
        total_annotations = total_class_counts[cat_id]
        unique_image_count = len(class_to_images[cat_id])
        locality_data.append((class_name, total_annotations, unique_image_count))

    # ê³ ìœ  ì´ë¯¸ì§€ ìˆ˜, ê·¸ ë‹¤ìŒ ì´ ì–´ë…¸í…Œì´ì…˜ ìˆ˜ë¡œ ì •ë ¬
    locality_data.sort(key=lambda x: (x[2], x[1]), reverse=True)

    if not locality_data:
        print(f"   â„¹ï¸ No classes found with {rare_threshold} or fewer annotations.")
        return

    # --- 4. ì‹œê°í™” ---
    class_names, total_counts, image_counts = zip(*locality_data)

    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(14, max(10, len(class_names) * 0.4))) # í´ë˜ìŠ¤ ìˆ˜ì— ë”°ë¼ ë†’ì´ ì¡°ì ˆ

    # ë§‰ëŒ€ ê·¸ë˜í”„: ë§‰ëŒ€ ê¸¸ì´ëŠ” 'ê³ ìœ  ì´ë¯¸ì§€ ìˆ˜'
    sns.barplot(x=list(image_counts), y=list(class_names), orient='h', ax=ax, color='skyblue')

    # ë§‰ëŒ€ ëì— 'ì´ ì–´ë…¸í…Œì´ì…˜ ìˆ˜'ë¥¼ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
    ax.bar_label(ax.containers[0], labels=[f'{c:,}' for c in total_counts], padding=5, fontsize=10, color='black')

    ax.set_title(f'Locality of Rare Classes (<= {rare_threshold} annotations)', fontsize=16)
    ax.set_xlabel('Number of Unique Images (Bar Length) & Total Annotations (Label)', fontsize=12)
    ax.set_ylabel('Class Name', fontsize=12)
    ax.set_xlim(right=max(total_counts) * 1.2) # í…ìŠ¤íŠ¸ê°€ ì˜ë¦¬ì§€ ì•Šë„ë¡ xì¶• ë²”ìœ„ í™•ì¥
    plt.tight_layout()

    # --- 5. ê²°ê³¼ ì €ì¥ ---
    save_file = figure_path / "rare_class_locality.png"
    plt.savefig(save_file)
    print(f"   âœ… Visualization saved to: {save_file}")

def test_report_rare_class_image_distribution():
    """
    100ê°œ ì´í•˜ì˜ ì–´ë…¸í…Œì´ì…˜ì„ ê°€ì§„ ì†Œìˆ˜ í´ë˜ìŠ¤ ê°ê°ì´
    ì–´ë–¤ ì´ë¯¸ì§€ì— ëª‡ ê°œì˜ ì–´ë…¸í…Œì´ì…˜ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("ğŸ“„ Generating rare class image distribution report...")

    # --- 1. ê²½ë¡œ ë° íŒŒë¼ë¯¸í„° ì„¤ì • ---
    base_dir = Path(os.getcwd()).resolve()
    data_path = base_dir / "assets"
    report_path = base_dir / "reports"
    report_path.mkdir(parents=True, exist_ok=True)

    rare_threshold = 100

    # --- 2. ë°ì´í„° ë¡œë“œ ---
    json_file_path = data_path / "merged_dataset.json"
    if not json_file_path.exists():
        print(f"âŒ Error: File not found at {json_file_path}")
        return

    print(f"   Loading data from {json_file_path}...")
    coco_data = load_json_data(json_file_path)
    annotations = coco_data.get("annotations", [])
    categories = coco_data.get("categories", [])
    images = coco_data.get("images", [])

    if not all([annotations, categories, images]):
        print("   âš ï¸ Annotations, categories, or images are missing in the JSON file.")
        return

    # --- 3. ë°ì´í„° ë¶„ì„ ---
    # ID-ì´ë¦„ ë§¤í•‘ ìƒì„±
    id_to_cat_name = {cat["id"]: cat["name"] for cat in categories}
    id_to_img_name = {img["id"]: img["file_name"] for img in images}

    # ì „ì²´ í´ë˜ìŠ¤ë³„ ì–´ë…¸í…Œì´ì…˜ ìˆ˜ ê³„ì‚°
    total_class_counts = Counter(ann["category_id"] for ann in annotations)

    # ì†Œìˆ˜ í´ë˜ìŠ¤(rare class) ID í•„í„°ë§
    rare_class_ids = {
        cat_id for cat_id, count in total_class_counts.items() if count <= rare_threshold
    }

    # ì†Œìˆ˜ í´ë˜ìŠ¤ì— ëŒ€í•´ {í´ë˜ìŠ¤ ID: {ì´ë¯¸ì§€ ID: ê°œìˆ˜}} í˜•íƒœë¡œ ì§‘ê³„
    class_image_counts = defaultdict(lambda: defaultdict(int))
    for ann in annotations:
        cat_id = ann["category_id"]
        if cat_id in rare_class_ids:
            class_image_counts[cat_id][ann["image_id"]] += 1

    # --- 4. ë¦¬í¬íŠ¸ ìƒì„± ---
    report_lines = []
    
    # í´ë˜ìŠ¤ ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë¦¬í¬íŠ¸ ì¼ê´€ì„± ìœ ì§€
    sorted_rare_class_ids = sorted(list(rare_class_ids), key=lambda cid: id_to_cat_name.get(cid, ''))

    for cat_id in sorted_rare_class_ids:
        class_name = id_to_cat_name.get(cat_id, f"Unknown({cat_id})")
        total_count = total_class_counts[cat_id]
        
        report_lines.append(f"Class: {class_name} (Total Annotations: {total_count})")
        
        # ì´ë¯¸ì§€ë³„ ë¶„í¬: ì´ë¯¸ì§€ ë‚´ ì–´ë…¸í…Œì´ì…˜ ê°œìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        image_distribution = sorted(
            class_image_counts[cat_id].items(), 
            key=lambda item: item[1], 
            reverse=True
        )
        
        for img_id, count in image_distribution:
            img_name = id_to_img_name.get(img_id, f"Unknown Image ID({img_id})")
            report_lines.append(f"  - Image: {img_name}, Annotations: {count}")
        report_lines.append("-" * 40)

    # --- 5. ê²°ê³¼ ì €ì¥ ---
    save_file = report_path / "rare_class_image_distribution.txt"
    with open(save_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(report_lines))
    
    print(f"   âœ… Report saved to: {save_file}")


if __name__ == "__main__":
    # data_pipeline()
    # test_visualize_class_distribution()
    # test_visualize_rare_class_locality()
    test_report_rare_class_image_distribution()